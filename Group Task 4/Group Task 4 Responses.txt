Section 1
i.	Yes, there is evidence of imbalance. In the logit output, there are several variables with significant p-values (< 0.05), including kwh_2009_09, question 420, and question 4701.2_1. Looking at the quick means test output, it appears that there are differences in the means between the treatment and control groups for some variables (kwh_2009_12, D_410_3, and D_405_2) that could be statistically significant. To determine whether this is the case, we did a “by-hand” t-test. Our suspicions were confirmed: the variables that we had identified had high t-values in the t-test output. This indicates that the treatment group was not as good as random assignment since certain pre-trial consumption values and survey responses are predictors of assignment to the treatment group.
ii.	Some of the variables that were significant in the logit model were also significant in the quick means comparison (kwh_2009_12), but others were only significant in the quick means test (kwh_2009_10, D_410_3). We would expect there to be more significant variables in the quick means test because of multicollinearity. If there is high or imperfect multicollinearity, it does not violate the OLS assumptions. However, it does inflate standard errors, which can cause variables to appear insignificant when they are actually significant. In other words, the estimates could be precise but not unbiased. 
iii.	The logit check is good because it gives you standard errors and p-values, but you may not trust the estimates in situations with large data sets whose overlapping variables run a higher risk of collinearity. In general, we expect standard errors to decrease with as the number of observations increases. However, we are concerned that some of the survey questions may be similar to one another, which would lead to higher multicollinearity and expand standard errors. The quick means test is easy to perform. However, it is not as rigorous as the two-sample t-test.
iv.	Questions 410, 420, and 43111 are redundant - they all determine the number of people in the household that are over/under 15. Questions 43521 and 5414 are also somewhat redundant - they both determine expected reductions in energy usage. Variables that should have been included are income level, type of home, type of appliances, and attitudes toward conservation.
Section 3
i.	The coefficient estimate for the treatment-trial interaction variable was not significant without the weights but became significant with the inclusion of the weights.
ii.	Without weights, logged energy consumption for households in the treatment group and in the trial period (i.e. those who actually received treatment) decreased by 0.008 kwh relative to those in the control group. Since the results are not statistically significant, however, we cannot conclude that the C4 treatment was effective in altering household behavior.
iii.	With weights, logged energy consumption for people in the treatment group and in the trial period decreased by 0.025 kwh relative to the control group. Assuming that the weights are proper, this means that the regression results were biased downwards in the initial results (without weights); when the weights were applied, the treatment effect increased four-fold. The coefficient estimate for the treatment effect is statistically significant in this case; however, even after weighting, the coefficient estimates for several of the survey response dummy variables are as large or larger than the treatment effect. Therefore, we conclude that the C4 treatment was not very effective. The results may be statistically significant, but they are not practically significant since the treatment effect appears rather weak.  
iv.	The weights we created theoretically rebalanced the dataset based on observable characteristics, but this dataset of observed characteristics also omitted many other variables that are significant predictors of energy consumption. In addition, some of the variables that the dataset does include were collinear. Furthermore, we did not attempt to restore balance based on any unobservables that may be confounding our estimates. In future models, we could use an instrumental variable approach in order to limit this potential endogeneity problem. Overall, our findings suggest that the weights derived from propensity score matching may not be entirely reliable and that our coefficient estimates should be interpreted with caution. 
